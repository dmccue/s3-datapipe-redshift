AWSTemplateFormatVersion: "2010-09-09"

Description: Example S3bucket with Lambda event trigger

Parameters:

  # Key:
  #   Description: S3 Object key
  #   Type: String
  #   Default: incoming/test.csv
  #
  # Body:
  #   Description: S3 Object body content
  #   Type: String
  #   Default: 0,"David",33

  BucketName:
    Type: String
    Description: S3 Bucket name

  PipelineName:
    Type: String
    Description: Pipeline reference Name

  LambdaFileHandlerName:
    Type: String
    Description: Name of Lambda file handler
    Default: MyS3FileHandler

Resources:


  Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    DependsOn: BucketPermission
    Properties:
      BucketName: !Ref BucketName
      NotificationConfiguration:
        LambdaConfigurations:
        - Event: "s3:ObjectCreated:*"
          Function: !GetAtt BucketWatcher.Arn
          Filter:
            S3Key:
              Rules:
                - Name: prefix
                  Value: incoming/
                - Name: suffix
                  Value: .csv

  BucketPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref BucketWatcher
      Principal: s3.amazonaws.com
      SourceAccount: !Ref "AWS::AccountId"
      SourceArn: !Sub "arn:aws:s3:::${BucketName}"

  # S3Object:
  #   Type: Custom::S3Object
  #   Properties:
  #     ServiceToken: !GetAtt S3ObjectFunction.Arn
  #     Bucket: !Ref Bucket
  #     Key: !Ref Key
  #     Body: !Ref Body


  myLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    Properties:
      LogGroupName: !Sub "/aws/lambda/${LambdaFileHandlerName}"
      RetentionInDays: 7


  BucketWatcher:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Ref LambdaFileHandlerName
      Description: Invokes handler for file creation
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Timeout: 30
      Runtime: python2.7
      MemorySize: 128
      Environment:
        Variables:
          PipelineName: !Ref PipelineName

      Code:
        ZipFile: !Sub |
          from __future__ import print_function
          import json, boto3, time, urllib, datetime, os

          DEBUG = True

          def lambda_handler(event, context):
            try:
              if DEBUG: print("DEBUG: Loading function at: " + str(datetime.datetime.now()))

              # Retrieve pipeline Name
              pipelineName = os.environ['PipelineName']
              if DEBUG: print("DEBUG: Retrieved ENV variable PipelineName: " + pipelineName)

              # Iniitialise boto client
              pipelineClient = boto3.client('datapipeline')

              # Lookup pipelineID from pipelineName
              pipelineID = None
              for item in pipelineClient.list_pipelines()['pipelineIdList']:
                if item['name'] == pipelineName:
                  pipelineID = item['id']
              if not pipelineID:
                print("Error: Unable to find PipelineName " + pipelineName)
                return false

              eventRecord = event['Records'][0]
              if DEBUG:
                print("DEBUG: Received event: " + str(event))
                print("DEBUG: Event time: " + str(eventRecord['eventTime']))
                print("DEBUG: Event region: " + str(eventRecord['awsRegion']))
                print("DEBUG: Event name: " + str(eventRecord['eventName']))
                print("DEBUG: S3 BucketName: " + str(eventRecord['s3']['bucket']['name']))
                print("DEBUG: S3 ObjectKey: " + str(eventRecord['s3']['object']['key']))

              # Create string variables
              inputS3Location='s3://' + str(eventRecord['s3']['bucket']['name']) + '/' + str(eventRecord['s3']['object']['key'])

              # Retrieve existing datapipeline definition
              pipelineDef = pipelineClient.get_pipeline_definition(pipelineId=pipelineID)
              if DEBUG: print("DEBUG: pipeline definition: " + str(pipelineDef))

              # Remove myInputS3Loc
              parameterValues = pipelineDef['parameterValues']
              parameterValues[:] = [x for x in parameterValues if x.get('id') != "myInputS3Loc"]
              if DEBUG: print("DEBUG: pipeline definition - myInputS3Loc: " + str(parameterValues))

              # Add myInputS3Loc
              pipelineValue = { 'id': 'myInputS3Loc' }
              pipelineValue['stringValue'] = inputS3Location
              parameterValues.append(pipelineValue)
              pipelineDef['parameterValues'] = parameterValues
              if DEBUG: print("DEBUG: Modified Pipeline Definition: " + str( pipelineDef ))

              # Validate pipeline definition
              responseValidation = pipelineClient.validate_pipeline_definition(
                pipelineId = pipelineID,
                parameterObjects = pipelineDef['parameterObjects'],
                parameterValues = pipelineDef['parameterValues'],
                pipelineObjects = pipelineDef['pipelineObjects']
              )
              if DEBUG: print("DEBUG: Validation: " + str(responseValidation))

              # Check no errors during Validation
              if responseValidation['errored']:
                print("Error: Validation Failed " + str(responseValidation))
                return false

              # Attempt to activate datapipeline
              if DEBUG: print("DEBUG: Activate PipelinePayload: " + str( pipelineDef['parameterValues'] ))
              response = pipelineClient.activate_pipeline(
                pipelineId = pipelineID,
                parameterValues = pipelineDef['parameterValues']
              )
              if DEBUG:
                print("DEBUG: Activated Pipeline: " + str( response ))
                print("DEBUG: Activated pipeline at: " + str(datetime.datetime.now()))
              return response

            except Exception as e:

              print("Error: " + str(e))
              raise e



  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: /
      ManagedPolicyArns:
      - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Policies:
      # - PolicyName: S3Policy
      #   PolicyDocument:
      #     Version: '2012-10-17'
      #     Statement:
      #       - Effect: Allow
      #         Action:
      #           - 's3:PutObject'
      #           - 'S3:DeleteObject'
      #         Resource: !Sub "arn:aws:s3:::${BucketName}/"
      - PolicyName: DataPipelinePolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Action:
                - 'datapipeline:*'
                - 'iam:PassRole'
              Resource: "*"


Outputs:

  BucketRef:
    Description: Name of bucket
    Value: !Ref Bucket
